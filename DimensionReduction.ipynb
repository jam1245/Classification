{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Dimensionality Reduction on HR Analytics Data \n",
    "\n",
    "In this notebook I will compare both **feature selection** and **feature extraction** for dimensionality reduction.\n",
    "\n",
    "Datset: [HR Analytics dataset](https://www.kaggle.com/ludobenistant/hr-analytics).\n",
    "##### NOTE\n",
    "\n",
    "The goal is the get the best performance from the **Naive Bayes** model using feature reduction techniques. \n",
    "We can expect that a different model may be more suitable; however, I want to only have a single moving part at a time so let's just stick with Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(18937)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "from sklearn.preprocessing import scale\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let'sload the HR dataset\n",
    "\n",
    "I'll load dataset into a DataFrame and shuffle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.612834</td>\n",
       "      <td>0.716102</td>\n",
       "      <td>3.803054</td>\n",
       "      <td>201.050337</td>\n",
       "      <td>3.498233</td>\n",
       "      <td>0.144610</td>\n",
       "      <td>0.238083</td>\n",
       "      <td>0.021268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.248631</td>\n",
       "      <td>0.171169</td>\n",
       "      <td>1.232592</td>\n",
       "      <td>49.943099</td>\n",
       "      <td>1.460136</td>\n",
       "      <td>0.351719</td>\n",
       "      <td>0.425924</td>\n",
       "      <td>0.144281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>245.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>310.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       satisfaction_level  last_evaluation  number_project  \\\n",
       "count        14999.000000     14999.000000    14999.000000   \n",
       "mean             0.612834         0.716102        3.803054   \n",
       "std              0.248631         0.171169        1.232592   \n",
       "min              0.090000         0.360000        2.000000   \n",
       "25%              0.440000         0.560000        3.000000   \n",
       "50%              0.640000         0.720000        4.000000   \n",
       "75%              0.820000         0.870000        5.000000   \n",
       "max              1.000000         1.000000        7.000000   \n",
       "\n",
       "       average_montly_hours  time_spend_company  Work_accident          left  \\\n",
       "count          14999.000000        14999.000000   14999.000000  14999.000000   \n",
       "mean             201.050337            3.498233       0.144610      0.238083   \n",
       "std               49.943099            1.460136       0.351719      0.425924   \n",
       "min               96.000000            2.000000       0.000000      0.000000   \n",
       "25%              156.000000            3.000000       0.000000      0.000000   \n",
       "50%              200.000000            3.000000       0.000000      0.000000   \n",
       "75%              245.000000            4.000000       0.000000      0.000000   \n",
       "max              310.000000           10.000000       1.000000      1.000000   \n",
       "\n",
       "       promotion_last_5years  \n",
       "count           14999.000000  \n",
       "mean                0.021268  \n",
       "std                 0.144281  \n",
       "min                 0.000000  \n",
       "25%                 0.000000  \n",
       "50%                 0.000000  \n",
       "75%                 0.000000  \n",
       "max                 1.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset location\n",
    "DATASET = '/dsa/data/all_datasets/HR_analytics.csv'\n",
    "assert os.path.exists(DATASET)\n",
    "\n",
    "# Load and shuffle\n",
    "dataset = pd.read_csv(DATASET).sample(frac = 1).reset_index(drop=True)\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print top 5 rows of the dataset to take a peak at the variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>sales</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.90</td>\n",
       "      <td>5</td>\n",
       "      <td>202</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>IT</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2</td>\n",
       "      <td>194</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>technical</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.47</td>\n",
       "      <td>2</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>hr</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.47</td>\n",
       "      <td>0.55</td>\n",
       "      <td>4</td>\n",
       "      <td>122</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>marketing</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.65</td>\n",
       "      <td>5</td>\n",
       "      <td>195</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>support</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.83</td>\n",
       "      <td>4</td>\n",
       "      <td>183</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>support</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction_level  last_evaluation  number_project  average_montly_hours  \\\n",
       "0                0.85             0.90               5                   202   \n",
       "1                0.12             0.60               2                   194   \n",
       "2                0.40             0.47               2                   136   \n",
       "3                0.47             0.55               4                   122   \n",
       "4                0.89             0.65               5                   195   \n",
       "5                0.80             0.83               4                   183   \n",
       "\n",
       "   time_spend_company  Work_accident  left  promotion_last_5years      sales  \\\n",
       "0                   3              0     0                      0         IT   \n",
       "1                   4              0     0                      0  technical   \n",
       "2                   3              0     1                      0         hr   \n",
       "3                   5              1     0                      0  marketing   \n",
       "4                   6              0     1                      0    support   \n",
       "5                   2              1     0                      1    support   \n",
       "\n",
       "   salary  \n",
       "0     low  \n",
       "1  medium  \n",
       "2  medium  \n",
       "3  medium  \n",
       "4     low  \n",
       "5     low  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[:6,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['satisfaction_level', 'last_evaluation', 'number_project',\n",
       "       'average_montly_hours', 'time_spend_company', 'Work_accident', 'left',\n",
       "       'promotion_last_5years', 'sales', 'salary'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns # check column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing\n",
    "\n",
    "In the dataset, \"sales\" and \"salary\" are string columns,\n",
    "which need some proccessing before I can start feature selection/extraction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>sales</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_high</th>\n",
       "      <th>salary_low</th>\n",
       "      <th>salary_medium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.90</td>\n",
       "      <td>5</td>\n",
       "      <td>202</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>IT</td>\n",
       "      <td>low</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2</td>\n",
       "      <td>194</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>technical</td>\n",
       "      <td>medium</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.47</td>\n",
       "      <td>2</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>hr</td>\n",
       "      <td>medium</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.47</td>\n",
       "      <td>0.55</td>\n",
       "      <td>4</td>\n",
       "      <td>122</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>marketing</td>\n",
       "      <td>medium</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.65</td>\n",
       "      <td>5</td>\n",
       "      <td>195</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>support</td>\n",
       "      <td>low</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.83</td>\n",
       "      <td>4</td>\n",
       "      <td>183</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>support</td>\n",
       "      <td>low</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.50</td>\n",
       "      <td>4</td>\n",
       "      <td>216</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>technical</td>\n",
       "      <td>low</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.59</td>\n",
       "      <td>4</td>\n",
       "      <td>197</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.53</td>\n",
       "      <td>4</td>\n",
       "      <td>192</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>IT</td>\n",
       "      <td>medium</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.68</td>\n",
       "      <td>3</td>\n",
       "      <td>226</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>technical</td>\n",
       "      <td>medium</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.66</td>\n",
       "      <td>3</td>\n",
       "      <td>151</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>technical</td>\n",
       "      <td>low</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.52</td>\n",
       "      <td>3</td>\n",
       "      <td>186</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>IT</td>\n",
       "      <td>medium</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    satisfaction_level  last_evaluation  number_project  average_montly_hours  \\\n",
       "0                 0.85             0.90               5                   202   \n",
       "1                 0.12             0.60               2                   194   \n",
       "2                 0.40             0.47               2                   136   \n",
       "3                 0.47             0.55               4                   122   \n",
       "4                 0.89             0.65               5                   195   \n",
       "5                 0.80             0.83               4                   183   \n",
       "6                 0.61             0.50               4                   216   \n",
       "7                 0.57             0.59               4                   197   \n",
       "8                 0.58             0.53               4                   192   \n",
       "9                 0.62             0.68               3                   226   \n",
       "10                0.67             0.66               3                   151   \n",
       "11                0.69             0.52               3                   186   \n",
       "\n",
       "    time_spend_company  Work_accident  left  promotion_last_5years      sales  \\\n",
       "0                    3              0     0                      0         IT   \n",
       "1                    4              0     0                      0  technical   \n",
       "2                    3              0     1                      0         hr   \n",
       "3                    5              1     0                      0  marketing   \n",
       "4                    6              0     1                      0    support   \n",
       "5                    2              1     0                      1    support   \n",
       "6                    2              0     0                      0  technical   \n",
       "7                    3              0     0                      0      sales   \n",
       "8                    4              0     0                      0         IT   \n",
       "9                    3              0     0                      0  technical   \n",
       "10                   3              0     0                      0  technical   \n",
       "11                   3              0     0                      0         IT   \n",
       "\n",
       "    salary  salary_high  salary_low  salary_medium  \n",
       "0      low            0           1              0  \n",
       "1   medium            0           0              1  \n",
       "2   medium            0           0              1  \n",
       "3   medium            0           0              1  \n",
       "4      low            0           1              0  \n",
       "5      low            0           1              0  \n",
       "6      low            0           1              0  \n",
       "7      low            0           1              0  \n",
       "8   medium            0           0              1  \n",
       "9   medium            0           0              1  \n",
       "10     low            0           1              0  \n",
       "11  medium            0           0              1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# create an Binarize object from the scikit learn labelBinarizer function \n",
    "encoder = preprocessing.LabelBinarizer()\n",
    "\n",
    "# this creates a numpy array of 1 and zeros on the salary column - for each categorical variable it codes a one or zero.\n",
    "salary_features = encoder.fit_transform(np.expand_dims(dataset.salary, 1))\n",
    "\n",
    "# this bit of code iterates over the encoder.classes_ object created above and \n",
    "# creates three new columns (one for every categorical variable).  Uses the categorical variable as a new column name \n",
    "# and stores the one or zero in each new column \n",
    "for j, _class in enumerate(encoder.classes_):\n",
    "    dataset.loc[:, 'salary_{}'.format(_class.replace('\\x20', '_'))] = salary_features[:, j]\n",
    "\n",
    "dataset.iloc[:12,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now please write similar code for \"sales\" column like what we just did above. Feel free to drop questions on disscussion board if you need clarification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['IT', 'technical', 'hr', 'marketing', 'support', 'sales',\n",
       "       'management', 'product_mng', 'RandD', 'accounting'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's first view the categorical variables in the sales column.  Looks like there's 10 different variables\n",
    "dataset.sales.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14999 entries, 0 to 14998\n",
      "Data columns (total 23 columns):\n",
      "satisfaction_level       14999 non-null float64\n",
      "last_evaluation          14999 non-null float64\n",
      "number_project           14999 non-null int64\n",
      "average_montly_hours     14999 non-null int64\n",
      "time_spend_company       14999 non-null int64\n",
      "Work_accident            14999 non-null int64\n",
      "left                     14999 non-null int64\n",
      "promotion_last_5years    14999 non-null int64\n",
      "sales                    14999 non-null object\n",
      "salary                   14999 non-null object\n",
      "salary_high              14999 non-null int64\n",
      "salary_low               14999 non-null int64\n",
      "salary_medium            14999 non-null int64\n",
      "sales_IT                 14999 non-null int64\n",
      "sales_RandD              14999 non-null int64\n",
      "sales_accounting         14999 non-null int64\n",
      "sales_hr                 14999 non-null int64\n",
      "sales_management         14999 non-null int64\n",
      "sales_marketing          14999 non-null int64\n",
      "sales_product_mng        14999 non-null int64\n",
      "sales_sales              14999 non-null int64\n",
      "sales_support            14999 non-null int64\n",
      "sales_technical          14999 non-null int64\n",
      "dtypes: float64(2), int64(19), object(2)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# create an Binarize object from the scikit learn labelBinarizer function \n",
    "encoder = preprocessing.LabelBinarizer()\n",
    "\n",
    "# this creates a numpy array of 1 and zeros on the sales column - for each 10 categorical variables it codes a one or zero.\n",
    "sales_features = encoder.fit_transform(np.expand_dims(dataset.sales, 1))\n",
    "\n",
    "# this bit of code iterates over the encoder.classes_ object created above and \n",
    "# creates three new columns (one for every categorical variable).  Uses the categorical variable as a new column name \n",
    "# and stores the one or zero in each new column \n",
    "for j, _class in enumerate(encoder.classes_):\n",
    "    dataset.loc[:, 'sales_{}'.format(_class.replace('\\x20', '_'))] = sales_features[:, j]\n",
    "\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I store feature columns (all columns except 'left', 'sales' and 'salary') to a new variable **X**.\n",
    "\n",
    "Then I'll store the label column into a new variable **y**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14999 entries, 0 to 14998\n",
      "Data columns (total 20 columns):\n",
      "satisfaction_level       14999 non-null float64\n",
      "last_evaluation          14999 non-null float64\n",
      "number_project           14999 non-null int64\n",
      "average_montly_hours     14999 non-null int64\n",
      "time_spend_company       14999 non-null int64\n",
      "Work_accident            14999 non-null int64\n",
      "promotion_last_5years    14999 non-null int64\n",
      "salary_high              14999 non-null int64\n",
      "salary_low               14999 non-null int64\n",
      "salary_medium            14999 non-null int64\n",
      "sales_IT                 14999 non-null int64\n",
      "sales_RandD              14999 non-null int64\n",
      "sales_accounting         14999 non-null int64\n",
      "sales_hr                 14999 non-null int64\n",
      "sales_management         14999 non-null int64\n",
      "sales_marketing          14999 non-null int64\n",
      "sales_product_mng        14999 non-null int64\n",
      "sales_sales              14999 non-null int64\n",
      "sales_support            14999 non-null int64\n",
      "sales_technical          14999 non-null int64\n",
      "dtypes: float64(2), int64(18)\n",
      "memory usage: 2.3 MB\n",
      "[[  8.50000000e-01   9.00000000e-01   5.00000000e+00   2.02000000e+02\n",
      "    3.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    1.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  1.20000000e-01   6.00000000e-01   2.00000000e+00   1.94000000e+02\n",
      "    4.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   1.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00]\n",
      " [  4.00000000e-01   4.70000000e-01   2.00000000e+00   1.36000000e+02\n",
      "    3.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   1.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   1.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  4.70000000e-01   5.50000000e-01   4.00000000e+00   1.22000000e+02\n",
      "    5.00000000e+00   1.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   1.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]]\n",
      "[0 0 1 ..., 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# make sure this code is selecting the columns desired \n",
    "newdata = dataset.iloc[:, np.r_[0:6, 7:8, 10:23]]\n",
    "\n",
    "# view output before it goes into an array \n",
    "newdata.info()\n",
    "\n",
    "# use iloc and np.r_ to select columns and store them into a new variable X - a numpy array \n",
    "X = np.array(dataset.iloc[:, np.r_[0:6, 7:8, 10:23]])\n",
    "\n",
    "# Grab the target variable and store it into a numpy array named y\n",
    "y = np.array(dataset.left)\n",
    "\n",
    "# take a look at the data \n",
    "print(X[:4])\n",
    "print(y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now create train/validate split (20% validation ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection and evaluation\n",
    "\n",
    "Steps I'll take:\n",
    "1. Initialize a feature selector\n",
    "2. Fit feature selector on training set\n",
    "3. Print indices of features selected, the \"support\".\n",
    "4. Train a Gaussian Naive Bayes model on selected features from training set.\n",
    "5. Evaluate the model by measuring its accuracy on the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.81535117e+02   4.48445122e-02   3.72329462e+00   7.94896891e+02\n",
      "   1.56525975e+02   2.51281160e+02   4.78547228e+01   1.61801609e+02\n",
      "   1.21291796e+02   3.75952950e+01   6.37107974e-01   2.80140334e+01\n",
      "   4.04950887e+00   1.07948130e+01   2.27176338e+01   6.14596997e-02\n",
      "   2.89620782e+00   4.43749081e-02   1.58555395e+00   5.10618897e+00]\n",
      "[0 3 4 5 7 8]\n",
      "Chi Square NB Model Score:  0.776333333333\n",
      "[[1801  497]\n",
      " [ 174  528]]\n",
      "Chi Square NB Model Accuracy:  0.776333333333\n",
      "Chi Square NB Model Precision:  0.776333333333\n",
      "Chi Square NB f1 score:  0.776333333333\n"
     ]
    }
   ],
   "source": [
    "# Feature Selection with Chi Square \n",
    "\n",
    "# STEP 1: initialize a feature selector \n",
    "selector = SelectKBest(chi2, k=6)\n",
    "\n",
    "# STEP 2: fit feature selector on training set \n",
    "selector.fit(X_train, y_train)\n",
    "print(selector.scores_)\n",
    "\n",
    "# STEP 3: print indicies of features selected - the support \n",
    "print(selector.get_support(True))\n",
    "\n",
    "# STEP 3a: reduciing the features into another dataframe \n",
    "# x2reduced = dataset.iloc[:, [0, 3, 4, 5, 6, 7, 8, 9, 11, 14]]\n",
    "\n",
    "# STEP 3b: printing a head w/column names of the reduced chi square dataframe \n",
    "#print(x2reduced.info())\n",
    "\n",
    "# STEP 4: train a Gaussian Naive Bayes model on selected features from training set \n",
    "# STEP 4a: Call selector.transform() method to select those feature columns from dataset\n",
    "X_train_selected = selector.transform(X_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# STEP 4b: create Gaussian Naive Bayes model and fit it to the selected features \n",
    "model = GaussianNB()\n",
    "model.fit(X_train_selected, y_train)\n",
    "\n",
    "# STEP 5: evaluate the model by measuring its accuracy on the test set \n",
    "score = model.score(X_test_selected, y_test)\n",
    "\n",
    "# print score \n",
    "print(\"Chi Square NB Model Score: \", score)\n",
    "\n",
    "# import other libraries for assessing model \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# make predictions with model\n",
    "predictions = model.predict(X_test_selected)\n",
    "\n",
    "# compute and view confusion matrix and store in confmatrix\n",
    "confmatrix = confusion_matrix(y_test, predictions.astype('i4'))\n",
    "print(confmatrix)\n",
    "\n",
    "# model accuracy computed and stored in accuracy \n",
    "# TP + TN / (TP + TN + FP + FN)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Chi Square NB Model Accuracy: \", accuracy)\n",
    "\n",
    "# precision calculated and stored in precision object \n",
    "# TP / (TP + FP)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "print(\"Chi Square NB Model Precision: \", precision)\n",
    "\n",
    "# compute f1 score and stored in object f1\n",
    "f1 = f1_score(y_test, predictions.astype('i4'), average='micro')\n",
    "print(\"Chi Square NB f1 score: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-Squared Statistic\n",
      "[  2.28193183e+02   2.64642367e-02   3.39020494e+00   9.45588933e+02\n",
      "   1.91708547e+02   3.06737710e+02   5.60448653e+01   2.01254596e+02\n",
      "   1.39446529e+02   4.05239215e+01   1.64371371e+00   3.08564507e+01\n",
      "   3.28865914e+00   1.13793626e+01   3.04516067e+01   1.04417630e-02\n",
      "   1.71479003e+00   1.06932924e+00   1.46206955e+00   4.94905082e+00]\n",
      "P-Values\n",
      "[  1.47701843e-051   8.70771716e-001   6.55847967e-002   1.20671018e-207\n",
      "   1.34710265e-043   1.12177164e-068   7.08359651e-014   1.11187274e-045\n",
      "   3.51760165e-032   1.94223558e-010   1.99816694e-001   2.77837057e-008\n",
      "   6.97599693e-002   7.42645951e-004   3.42299713e-008   9.18609877e-001\n",
      "   1.90365066e-001   3.01097003e-001   2.26601121e-001   2.61049970e-002]\n"
     ]
    }
   ],
   "source": [
    "# looking at the Chi Square Statistic and the p-values \n",
    "chi2_sklearn, pvalue_sklearn = chi2(X, y)\n",
    "print(\"Chi-Squared Statistic\")\n",
    "print(chi2_sklearn)\n",
    "\n",
    "print(\"P-Values\")\n",
    "print(pvalue_sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 8]\n",
      "mutal info NB Model Score:  0.815\n"
     ]
    }
   ],
   "source": [
    "# Feature Selection with Mutual Info Session \n",
    "\n",
    "def mutual_info_session():\n",
    "    selector = SelectKBest(mutual_info_classif, k=6)\n",
    "    selector.fit(X_train, y_train)\n",
    "    print(selector.get_support(True))\n",
    "    model = GaussianNB()\n",
    "    model.fit(selector.transform(X_train), y_train)\n",
    "    return model.score(selector.transform(X_test), y_test)\n",
    "    \n",
    "mutal_info_score = mutual_info_session()\n",
    "\n",
    "print(\"mutal info NB Model Score: \", mutal_info_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score [  2.12645419e+03   1.10545493e+00   9.30131625e+00   6.43349097e+01\n",
      "   2.60703997e+02   3.01229493e+02   4.90898656e+01   1.78952559e+02\n",
      "   2.40808861e+02   6.64511362e+01   6.94325255e-01   2.96214326e+01\n",
      "   4.26421215e+00   1.13838814e+01   2.37153460e+01   6.52048129e-02\n",
      "   3.08054664e+00   6.13398427e-02   1.86225954e+00   6.23888498e+00]\n",
      "Selected indices [0 4 5 7 8 9]\n",
      "F-Regression NB Model Score:  0.767333333333\n",
      "[[1753  545]\n",
      " [ 153  549]]\n",
      "F-Regression NB Model Accuracy:  0.767333333333\n",
      "F-Regression NB Model Precision:  0.767333333333\n",
      "F-Regression NB f1 score:  0.767333333333\n"
     ]
    }
   ],
   "source": [
    "# Feature Selection with F-Regression \n",
    "\n",
    "selector = SelectKBest(f_regression, k=6)\n",
    "selector.fit(X_train, y_train)\n",
    "print('score', selector.scores_)\n",
    "print('Selected indices', selector.get_support(True))\n",
    "\n",
    "# reduciing the features into another dataframe \n",
    "#x2reduced = newdata.iloc[:, [0, 4, 5, 7, 8] # when selecting 5 features \n",
    "#x2reduced = dataset.iloc[:, [0, 3, 4, 5, 6, 7, 8, 9, 11, 14]]  # when selecting 10 features \n",
    "\n",
    "#x2reduced.info() # note these were the same columns selected in the chi square feature selection \n",
    "\n",
    "# train a Gaussian Naive Bayes model on selected features from training set \n",
    "X_train_selected = selector.transform(X_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# create Gaussian Naive Bayes model and fit it to the selected features \n",
    "model = GaussianNB()\n",
    "model.fit(X_train_selected, y_train)\n",
    "\n",
    "# evaluate the model by measuring its accuracy on the test set \n",
    "score = model.score(X_test_selected, y_test)\n",
    "\n",
    "print(\"F-Regression NB Model Score: \", score)\n",
    "\n",
    "# make predictions with model\n",
    "predictions = model.predict(X_test_selected)\n",
    "\n",
    "# compute and view confusion matrix and store in confmatrix\n",
    "confmatrix = confusion_matrix(y_test, predictions.astype('i4'))\n",
    "print(confmatrix)\n",
    "\n",
    "# model accuracy computed and stored in accuracy \n",
    "# TP + TN / (TP + TN + FP + FN)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"F-Regression NB Model Accuracy: \", accuracy)\n",
    "\n",
    "# precision calculated and stored in precision object \n",
    "# TP / (TP + FP)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "print(\"F-Regression NB Model Precision: \", precision)\n",
    "\n",
    "# compute f1 score and stored in object f1\n",
    "f1 = f1_score(y_test, predictions.astype('i4'), average='micro')\n",
    "print(\"F-Regression NB f1 score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a minute to reflect on which feature selector is suitable for the job."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "It appears as though the mutual info session feature selection method scored best among the three NB models.  In all situations I extracted different numbers of features ranging from 5-10 features and the mutual info feature selection method picked different variables (features) from the dataset and performed better in each situation.  The f-regression and chi square methods generally selected the exact same features in my data when I adjusted the number - in turn resulting in very similar scores when I rean the model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select the features"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "I ended up testing the number of features going from 5-10 features.  There might be a better way to approach this, but I settled on 6 which seemed to give a decent NB sore when using the mutual selection feature selection method.  I got about the same results when I selected 7 features and as I added features the model score started dropping.  I figured perhaps 6 features also makes for a more simple model and fewer features can also help when explaining the model to others. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Feature extraction\n",
    "\n",
    "In this section I will use both **Principle Component Analysis** or **Factor Analysis** for feature extraction.\n",
    "\n",
    "Steps:\n",
    "1. Initialize the PCA and/or FactorAnalysis\n",
    "2. Fit feature extractor on training set.\n",
    "4. Train a Gaussian Naive Bayes model on selected features from training set.\n",
    "5. Evaluate the model by measuring its accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "The PCA analysis spreads out the data points so differences between features are clearer when modeling them together.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  9.97999534e-01   8.69342838e-04   4.73823077e-04   1.82844960e-04\n",
      "   9.48675247e-05]\n",
      "Features shape (14999, 5)\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=5)\n",
    "pca.fit(X)\n",
    "print(pca.explained_variance_ratio_)\n",
    "X_features = pca.transform(X)\n",
    "print('Features shape', X_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a scree plot of **explained variance ratio** for extracted features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total expained variance ratio 0.999620412718\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f84dd1fec18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_ticks = np.arange(len(pca.components_))+1\n",
    "\n",
    "plt.xticks(x_ticks)\n",
    "plt.plot(x_ticks, pca.explained_variance_ratio_)\n",
    "print('total expained variance ratio', np.sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I'm running a NB classifier on the PCA results to see how the model scores. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA NB Model Score:  0.778333333333\n",
      "[[2260   23]\n",
      " [ 642   75]]\n",
      "PCA NB Model Accuracy:  0.778333333333\n",
      "PCA NB Model Precision:  0.778333333333\n",
      "PCA NB f1 score:  0.778333333333\n"
     ]
    }
   ],
   "source": [
    "# X_features comes from the pca cells above \n",
    "X_PCA_train, X_PCA_test, y_train, y_test = train_test_split(X_features, y, test_size=0.20)\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(X_PCA_train, y_train)\n",
    "\n",
    "# evaluate the model by measuring its accuracy on the test set \n",
    "score = model.score(X_PCA_test, y_test)\n",
    "print(\"PCA NB Model Score: \", score)\n",
    "\n",
    "\n",
    "# make predictions with model\n",
    "predictions = model.predict(X_PCA_test)\n",
    "\n",
    "# compute and view confusion matrix and store in confmatrix\n",
    "confmatrix = confusion_matrix(y_test, predictions.astype('i4'))\n",
    "print(confmatrix)\n",
    "\n",
    "# model accuracy computed and stored in accuracy \n",
    "# TP + TN / (TP + TN + FP + FN)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"PCA NB Model Accuracy: \", accuracy)\n",
    "\n",
    "# precision calculated and stored in precision object \n",
    "# TP / (TP + FP)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "print(\"PCA NB Model Precision: \", precision)\n",
    "\n",
    "# compute f1 score and stored in object f1\n",
    "f1 = f1_score(y_test, predictions.astype('i4'), average='micro')\n",
    "print(\"PCA NB f1 score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll attempt to run the factor analysis and model the data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape (14999, 5)\n",
      "Factor Analysis NB Model Score:  0.762666666667\n",
      "[[2103  183]\n",
      " [ 529  185]]\n",
      "FA NB Model Accuracy:  0.762666666667\n",
      "FA NB Model Precision:  0.762666666667\n",
      "FA NB f1 score:  0.762666666667\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# transform features \n",
    "fa = FactorAnalysis(n_components=5)\n",
    "X_FA_features = fa.fit_transform(X)\n",
    "print('Features shape', X_FA_features.shape)\n",
    "\n",
    "# split transformed features into training and testing sets \n",
    "X_FA_train, X_FA_test, y_train, y_test = train_test_split(X_FA_features, y, test_size=0.20)\n",
    "\n",
    "# get NB model and fit it to FA tranformed training data \n",
    "model = GaussianNB()\n",
    "model.fit(X_FA_train, y_train)\n",
    "\n",
    "# evaluate the model by measuring its accuracy on the test set \n",
    "score = model.score(X_FA_test, y_test)\n",
    "print(\"Factor Analysis NB Model Score: \", score)\n",
    "\n",
    "# make predictions with model\n",
    "predictions = model.predict(X_FA_test)\n",
    "\n",
    "# compute and view confusion matrix and store in confmatrix\n",
    "confmatrix = confusion_matrix(y_test, predictions.astype('i4'))\n",
    "print(confmatrix)\n",
    "\n",
    "# model accuracy computed and stored in accuracy \n",
    "# TP + TN / (TP + TN + FP + FN)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"FA NB Model Accuracy: \", accuracy)\n",
    "\n",
    "# precision calculated and stored in precision object \n",
    "# TP / (TP + FP)\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "print(\"FA NB Model Precision: \", precision)\n",
    "\n",
    "# compute f1 score and stored in object f1\n",
    "f1 = f1_score(y_test, predictions.astype('i4'), average='micro')\n",
    "print(\"FA NB f1 score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Thoughts"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The feature extraction method performed about the same as the feature selection method.  There's actually not much difference. Depending on the use situation, one would probably have more luck explaining the results of the feature slection process because it is simplier - avoiding statistical transformations. Using the mutual selection feature selection method we were able to yield higher modeling scores so that might give us an advantage over the feature extraction approach in this situation.  It might help to test the model on more new data to see if there could be some overfitting happening on our data - not generalizing enough to new data.   "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Last note on feature selection. Here I extracted the features that have the best ability to predict if an employee leaves the company. These features have the strongest relationship to an employee leaving the job and therefore are the best features to use when predicting employee retention.  Here we could probably get better results with another model, but here it's nice to have a good reference point on feature feature selection/dimensionality reduction without worrying to much about the modeling.   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
