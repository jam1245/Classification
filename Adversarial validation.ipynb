{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversarial Validation\n",
    "\n",
    "#### How similar are the train and test data?\n",
    "\n",
    "In this notebook, I'm going to run through a process called adversarial validation.  This will help us understand if our training and testing datasets are similar.  If they are different, we know that it will be very challenging to train a model that can predict outcomes in the testing dataset.  So let's walk through the process using some recent data.  \n",
    "\n",
    "Part One will test this on a real dataset - in this case the ACLED Data we've been working with.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import os, sys\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the data\n",
    "\n",
    "We will import the data set and drop unnecessary columns.  Shuffling a data set is always good practice before running it through a model.  There could be longitudinal patterns in there that could cause the model not to generalize well with future data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_date</th>\n",
       "      <th>year</th>\n",
       "      <th>actor1</th>\n",
       "      <th>admin1</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5058</th>\n",
       "      <td>14-Nov-15</td>\n",
       "      <td>2015</td>\n",
       "      <td>Military Forces of Nigeria (2015-)</td>\n",
       "      <td>Borno</td>\n",
       "      <td>11.8464</td>\n",
       "      <td>13.1603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2909</th>\n",
       "      <td>24-Apr-17</td>\n",
       "      <td>2017</td>\n",
       "      <td>Unidentified Communal Militia (Nigeria)</td>\n",
       "      <td>Lagos</td>\n",
       "      <td>6.5263</td>\n",
       "      <td>3.3571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8990</th>\n",
       "      <td>23-Feb-13</td>\n",
       "      <td>2013</td>\n",
       "      <td>Rioters (Nigeria)</td>\n",
       "      <td>Taraba</td>\n",
       "      <td>7.8500</td>\n",
       "      <td>9.7833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7487</th>\n",
       "      <td>25-May-14</td>\n",
       "      <td>2014</td>\n",
       "      <td>Boko Haram - Jamatu Ahli is-Sunnah lid-Dawatai...</td>\n",
       "      <td>Borno</td>\n",
       "      <td>10.6129</td>\n",
       "      <td>12.1946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5898</th>\n",
       "      <td>11-Apr-15</td>\n",
       "      <td>2015</td>\n",
       "      <td>Unidentified Armed Group (Nigeria)</td>\n",
       "      <td>Ondo</td>\n",
       "      <td>6.5879</td>\n",
       "      <td>4.7436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     event_date  year                                             actor1  \\\n",
       "5058  14-Nov-15  2015                 Military Forces of Nigeria (2015-)   \n",
       "2909  24-Apr-17  2017            Unidentified Communal Militia (Nigeria)   \n",
       "8990  23-Feb-13  2013                                  Rioters (Nigeria)   \n",
       "7487  25-May-14  2014  Boko Haram - Jamatu Ahli is-Sunnah lid-Dawatai...   \n",
       "5898  11-Apr-15  2015                 Unidentified Armed Group (Nigeria)   \n",
       "\n",
       "      admin1  latitude  longitude  \n",
       "5058   Borno   11.8464    13.1603  \n",
       "2909   Lagos    6.5263     3.3571  \n",
       "8990  Taraba    7.8500     9.7833  \n",
       "7487   Borno   10.6129    12.1946  \n",
       "5898    Ondo    6.5879     4.7436  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Nigeria_Large.csv')\n",
    "\n",
    "# drop columns we don't need \n",
    "df = df.drop(['data_id', 'iso', 'event_id_cnty', 'event_id_no_cnty', 'time_precision', 'location', 'fatalities',\n",
    "              'event_type', 'assoc_actor_1', 'inter1', 'actor2', 'assoc_actor_2', 'inter2', \n",
    "              'interaction', 'region', 'country', 'admin2', 'admin3', 'geo_precision', 'source', \n",
    "             'source_scale', 'notes', 'timestamp', 'iso3'], axis=1)\n",
    "\n",
    "\n",
    "# shuffle dataframe\n",
    "df = shuffle(df)\n",
    "\n",
    "# look at the first few rows. \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_date</th>\n",
       "      <th>year</th>\n",
       "      <th>actor1</th>\n",
       "      <th>admin1</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>13 April 2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>Unidentified Armed Group (Nigeria)</td>\n",
       "      <td>Benue</td>\n",
       "      <td>7.3667</td>\n",
       "      <td>9.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>09 February 2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>Boko Haram - Wilayat Gharb Ifriqiyyah</td>\n",
       "      <td>Adamawa</td>\n",
       "      <td>10.8667</td>\n",
       "      <td>13.5833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>22 February 2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>Fulani Ethnic Militia (Nigeria)</td>\n",
       "      <td>Benue</td>\n",
       "      <td>7.8469</td>\n",
       "      <td>8.8546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>10 March 2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>Unidentified Armed Group (Nigeria)</td>\n",
       "      <td>Imo</td>\n",
       "      <td>5.3321</td>\n",
       "      <td>7.1447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>04 March 2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>Rioters (Nigeria)</td>\n",
       "      <td>Lagos</td>\n",
       "      <td>6.4531</td>\n",
       "      <td>3.3958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           event_date  year                                 actor1   admin1  \\\n",
       "133     13 April 2019  2019     Unidentified Armed Group (Nigeria)    Benue   \n",
       "614  09 February 2019  2019  Boko Haram - Wilayat Gharb Ifriqiyyah  Adamawa   \n",
       "488  22 February 2019  2019        Fulani Ethnic Militia (Nigeria)    Benue   \n",
       "334     10 March 2019  2019     Unidentified Armed Group (Nigeria)      Imo   \n",
       "408     04 March 2019  2019                      Rioters (Nigeria)    Lagos   \n",
       "\n",
       "     latitude  longitude  \n",
       "133    7.3667     9.0500  \n",
       "614   10.8667    13.5833  \n",
       "488    7.8469     8.8546  \n",
       "334    5.3321     7.1447  \n",
       "408    6.4531     3.3958  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "new_data = pd.read_csv('Nigeria_12_15_2018_5_15_2019.csv')\n",
    "\n",
    "# drop columns we don't need \n",
    "new_data = new_data.drop(['data_id', 'iso', 'event_id_cnty', 'event_id_no_cnty', 'time_precision', 'location', 'fatalities',\n",
    "              'event_type', 'assoc_actor_1', 'inter1', 'actor2', 'assoc_actor_2', 'inter2', \n",
    "              'interaction', 'region', 'country', 'admin2', 'admin3', 'geo_precision', 'source', \n",
    "             'source_scale', 'notes', 'timestamp', 'iso3', \"sub_event_type\"], axis=1)\n",
    "\n",
    "\n",
    "# shuffle dataframe\n",
    "new_data = shuffle(new_data)\n",
    "\n",
    "# look at the first few rows. \n",
    "new_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               year      latitude     longitude\n",
      "count  13261.000000  13261.000000  13261.000000\n",
      "mean    2012.898349      8.434394      8.142161\n",
      "std        5.171428      2.543484      3.160536\n",
      "min     1997.000000      4.286500      2.722200\n",
      "25%     2012.000000      6.335000      6.000000\n",
      "50%     2014.000000      7.854500      7.533300\n",
      "75%     2017.000000     10.799400      9.900000\n",
      "max     2018.000000     13.711700     14.650000\n",
      "              year    latitude   longitude\n",
      "count   938.000000  938.000000  938.000000\n",
      "mean   2018.906183    8.854114    8.064086\n",
      "std       0.291729    2.773835    3.045769\n",
      "min    2018.000000    4.452200    2.750000\n",
      "25%    2019.000000    6.404175    6.311600\n",
      "50%    2019.000000    8.916700    7.282150\n",
      "75%    2019.000000   11.747000    9.011125\n",
      "max    2019.000000   13.695700   14.472400\n"
     ]
    }
   ],
   "source": [
    "def describe_df(df):\n",
    "    stats_df = df.describe()\n",
    "    stats_df.append(pd.Series(df.isna().any(), name='nans'))\n",
    "    return stats_df\n",
    "\n",
    "print(describe_df(df))\n",
    "print(describe_df(new_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df\n",
    "test = new_data\n",
    "features = train.columns\n",
    "train['target'] = 0\n",
    "test['target'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['event_date', 'year', 'actor1', 'admin1', 'latitude', 'longitude'], dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = pd.concat([df, new_data], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_test['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       event_date_01 February 2019  event_date_01 January 2019  \\\n",
      "4055                             0                           0   \n",
      "8972                             0                           0   \n",
      "10881                            0                           0   \n",
      "11947                            0                           0   \n",
      "12890                            0                           0   \n",
      "\n",
      "       event_date_01 March 2019  event_date_02 April 2019  \\\n",
      "4055                          0                         0   \n",
      "8972                          0                         0   \n",
      "10881                         0                         0   \n",
      "11947                         0                         0   \n",
      "12890                         0                         0   \n",
      "\n",
      "       event_date_02 February 2019  event_date_02 January 2019  \\\n",
      "4055                             0                           0   \n",
      "8972                             0                           0   \n",
      "10881                            0                           0   \n",
      "11947                            0                           0   \n",
      "12890                            0                           0   \n",
      "\n",
      "       event_date_02 March 2019  event_date_02 May 2019  \\\n",
      "4055                          0                       0   \n",
      "8972                          0                       0   \n",
      "10881                         0                       0   \n",
      "11947                         0                       0   \n",
      "12890                         0                       0   \n",
      "\n",
      "       event_date_03 April 2019  event_date_03 February 2019       ...        \\\n",
      "4055                          0                            0       ...         \n",
      "8972                          0                            0       ...         \n",
      "10881                         0                            0       ...         \n",
      "11947                         0                            0       ...         \n",
      "12890                         0                            0       ...         \n",
      "\n",
      "       admin1_Ogun  admin1_Ondo  admin1_Osun  admin1_Oyo  admin1_Plateau  \\\n",
      "4055             0            0            0           0               0   \n",
      "8972             0            0            0           0               0   \n",
      "10881            0            0            0           0               0   \n",
      "11947            0            0            0           0               0   \n",
      "12890            0            0            0           0               0   \n",
      "\n",
      "       admin1_Rivers  admin1_Sokoto  admin1_Taraba  admin1_Yobe  \\\n",
      "4055               0              0              0            0   \n",
      "8972               0              0              1            0   \n",
      "10881              0              0              0            0   \n",
      "11947              0              0              0            0   \n",
      "12890              0              0              0            0   \n",
      "\n",
      "       admin1_Zamfara  \n",
      "4055                0  \n",
      "8972                0  \n",
      "10881               0  \n",
      "11947               0  \n",
      "12890               0  \n",
      "\n",
      "[5 rows x 5051 columns]\n"
     ]
    }
   ],
   "source": [
    "# encode the data using pandas get_dummies\n",
    "feat = pd.get_dummies(train_test)\n",
    "# Display the first 5 rows to see how the data has changed. Note how we have wide data now.  \n",
    "print(feat.iloc[:,5:].head(5))\n",
    "\n",
    "train_test = feat\n",
    "\n",
    "features = train_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "Training until validation scores don't improve for 1400 rounds.\n",
      "[1000]\ttraining's auc: 1\tvalid_1's auc: 1\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 1\tvalid_1's auc: 1\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 1400 rounds.\n",
      "[1000]\ttraining's auc: 1\tvalid_1's auc: 1\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 1\tvalid_1's auc: 1\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 1400 rounds.\n",
      "[1000]\ttraining's auc: 1\tvalid_1's auc: 1\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 1\tvalid_1's auc: 1\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 1400 rounds.\n",
      "[1000]\ttraining's auc: 1\tvalid_1's auc: 1\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 1\tvalid_1's auc: 1\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 1400 rounds.\n",
      "[1000]\ttraining's auc: 1\tvalid_1's auc: 1\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 1\tvalid_1's auc: 1\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import model_selection, preprocessing, metrics\n",
    "\n",
    "param = {'num_leaves': 50,\n",
    "         'min_data_in_leaf': 30, \n",
    "         'objective':'binary',\n",
    "         'max_depth': 5,\n",
    "         'learning_rate': 0.006,\n",
    "         \"min_child_samples\": 20,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9 ,\n",
    "         \"bagging_seed\": 27,\n",
    "         \"metric\": 'auc',\n",
    "         \"verbosity\": -1}\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "oof = np.zeros(len(train_test))\n",
    "\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_test.values, target)):\n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train_test.iloc[trn_idx][features], label=target[trn_idx])\n",
    "    val_data = lgb.Dataset(train_test.iloc[val_idx][features], label=target[val_idx])\n",
    "\n",
    "    num_round = 30000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds = 1400)\n",
    "    oof[val_idx] = clf.predict(train_test.iloc[val_idx][features], num_iteration=clf.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(target, oof)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we would like to see a score of around .50 which let's us know that the two datasets are identitcal.  Here we get a score of 1.0 which leads us to believe there is a huge difference in the training and testing dataset.  It would be very difficult to train a model to predict anything of value in the test dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_test.drop([ 'target'], axis = 1)\n",
    "y = train_test.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    5.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.metrics import roc_auc_score as AUC\n",
    "\n",
    "clf = RF(n_estimators = 100, verbose = True, n_jobs = -1)\n",
    "clf.fit(x, y)\n",
    "\n",
    "p = clf.predict_proba( x )[:,1]\n",
    "auc = AUC( y, p )\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part II Adversarial Validation on a Currated Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's run through the same process on a currated dataset from the ML learning repository.  \n",
    "\n",
    "In this case we'll use the red wine dataset.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_url = 'http://mlr.cs.umass.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
    "df = pd.read_csv(dataset_url, sep=';')\n",
    "\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "train = train[train.columns[2:]]\n",
    "test = test[test.columns[1:]]\n",
    "\n",
    "features = train.columns\n",
    "train['target'] = 0\n",
    "test['target'] = 1\n",
    "\n",
    "train_test = pd.concat([train, test], axis =0)\n",
    "\n",
    "target = train_test['target'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "Training until validation scores don't improve for 1400 rounds.\n",
      "[1000]\ttraining's auc: 0.94561\tvalid_1's auc: 0.480286\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's auc: 0.696082\tvalid_1's auc: 0.550201\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 1400 rounds.\n",
      "[1000]\ttraining's auc: 0.94671\tvalid_1's auc: 0.501313\n",
      "[2000]\ttraining's auc: 0.978154\tvalid_1's auc: 0.506002\n",
      "[3000]\ttraining's auc: 0.989942\tvalid_1's auc: 0.503438\n",
      "Early stopping, best iteration is:\n",
      "[1842]\ttraining's auc: 0.975501\tvalid_1's auc: 0.508502\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 1400 rounds.\n",
      "[1000]\ttraining's auc: 0.936589\tvalid_1's auc: 0.489143\n",
      "Early stopping, best iteration is:\n",
      "[200]\ttraining's auc: 0.84325\tvalid_1's auc: 0.513714\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 1400 rounds.\n",
      "[1000]\ttraining's auc: 0.941294\tvalid_1's auc: 0.492371\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's auc: 0.676546\tvalid_1's auc: 0.537143\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 1400 rounds.\n",
      "[1000]\ttraining's auc: 0.923709\tvalid_1's auc: 0.488225\n",
      "[2000]\ttraining's auc: 0.967565\tvalid_1's auc: 0.490112\n",
      "[3000]\ttraining's auc: 0.98324\tvalid_1's auc: 0.492977\n",
      "[4000]\ttraining's auc: 0.988965\tvalid_1's auc: 0.490531\n",
      "Early stopping, best iteration is:\n",
      "[3043]\ttraining's auc: 0.983622\tvalid_1's auc: 0.494514\n"
     ]
    }
   ],
   "source": [
    "param = {'num_leaves': 50,\n",
    "         'min_data_in_leaf': 30, \n",
    "         'objective':'binary',\n",
    "         'max_depth': 5,\n",
    "         'learning_rate': 0.006,\n",
    "         \"min_child_samples\": 20,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9 ,\n",
    "         \"bagging_seed\": 27,\n",
    "         \"metric\": 'auc',\n",
    "         \"verbosity\": -1}\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "oof = np.zeros(len(train_test))\n",
    "\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_test.values, target)):\n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train_test.iloc[trn_idx][features], label=target[trn_idx])\n",
    "    val_data = lgb.Dataset(train_test.iloc[val_idx][features], label=target[val_idx])\n",
    "\n",
    "    num_round = 30000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds = 1400)\n",
    "    oof[val_idx] = clf.predict(train_test.iloc[val_idx][features], num_iteration=clf.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5136679046129788"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(target, oof)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that we're nearly at the 0.5 mark we be certain that a training and testing dataset from the red wine source are nearly identical.  This is somewhat expected since it's from a trusted machine learning repository.  In the wild you're not always going to see identical training and testing datasets. Therefore, it's important to know recognize the differences and adversarial validation can be a really helpful technique for those doing machine learning in the wild.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
